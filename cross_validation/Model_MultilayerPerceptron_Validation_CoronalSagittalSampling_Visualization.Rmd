---
title: "Multilayer Perceptron Validation Experiments: Visualization"
subtitle: "Mouse-Human Mapping"
author: "Antoine Beauchamp"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  html_document:
    theme: paper
    highlight: pygments
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.width = 10,
                      fig.height = 8)
```


```{r}
suppressPackageStartupMessages(library(tidyverse))

path <- "/projects/abeauchamp/Projects/MouseHumanMapping/Paper_Descriptive/Data/ValidationExperiments/"
```

# Append new data

```{r}
appendDatasets <- TRUE
labels <- "Region67"
imputation <- "ImputeKNN"

if (appendDatasets) {
  
  #Set basename for files we want to append
  filebase <- str_c("MLP_Validation_CoronalSagittalSampling_", labels, "_", imputation)
  
  #Get the full file names we want to append (new files have suffix _temp)
  files <- str_subset(list.files(path), str_c(filebase, "_temp"))
  
  #If no new files, don't do anything. Otherwise import and concat
  if (length(files) == 0){
    message(str_c("No new files to append for labels ", labels, ", imputation ", imputation))
  } else {
    
    #If the compiled data already exists, import it. Otherwise create it
    if (str_c(filebase, ".csv") %in% list.files(path)){
      dfOut <- read_csv(str_c(path, filebase, ".csv"))
    } else {
      dfOut <- tibble()
    }
    
    #For every new file, import and concatenate
    filepaths <- str_c(path, files)
    for(file in filepaths){
      dfIn <- suppressMessages(read_csv(file))
      dfOut <- bind_rows(dfOut, dfIn)
    }
    
    #Write out the updated compiled data
    fileout <- str_c(path, filebase, ".csv")
    write_csv(dfOut, path = fileout)
  }
}
```



# Labels: 5; Imputation: Medians

```{r}
#Import data
labels <- "Region5"
imputation <- "ImputeMedians"
filepath <- str_c(path, "MLP_Validation_CoronalSagittalSampling_", labels, "_", imputation, ".csv")
dfPerformance_Region5_ImputeMedians <- suppressMessages(read_csv(filepath))

#Gather training and validation accuracies into one column
dfPlot_Region5_ImputeMedians <- dfPerformance_Region5_ImputeMedians %>% 
  gather(key = "dataset", 
         value = "accuracy",
         train_accuracy:val_accuracy)

Dropout <- 0
l2 <- 1e-6

dfPlot_Region5_ImputeMedians %>% 
  filter(dropout == Dropout,
         weight_decay == l2) %>% 
  ggplot(aes(x = hidden_units, 
             y = accuracy,
             shape = dataset,
             col = factor(hidden_layers))) + 
  geom_jitter(width=10,
              alpha = 0.3,
              size = 4) + 
  coord_cartesian(ylim = c(0.7,1)) + 
  scale_x_continuous(breaks = seq(0,1000,200)) +
  scale_y_continuous(breaks = seq(0,1,0.2)) +
  scale_shape_discrete(labels = c("Training", "Validation")) + 
  labs(x = "Number of hidden units", 
       y = "Accuracy",
       shape = "Dataset",
       col = "Hidden layers",
       caption = "Training and validation sets generated by random sampling of coronal and sagittal ISH datasets",
       title = "Neural net performance (Labels: 5, Imputation: Medians)",
       subtitle = str_c("Dropout = ", Dropout, "; Weight decay = ", l2)) + 
  theme_bw()
```

```{r}
dfPlot_Region5_ImputeMedians %>% 
  filter(dataset == "val_accuracy") %>% 
  group_by(hidden_units, hidden_layers, dropout, weight_decay) %>% 
  summarise(accuracy = mean(accuracy)) %>% 
  ungroup() %>% 
  filter(accuracy == max(accuracy))
```


# Labels: 67; Imputation: Medians

```{r}
#Import data
labels <- "Region67"
imputation <- "ImputeMedians"
filepath <- str_c(path, "MLP_Validation_CoronalSagittalSampling_", labels, "_", imputation, ".csv")
dfPerformance_Region67_ImputeMedians <- suppressMessages(read_csv(filepath))

#Gather training and validation accuracies into one column
dfPlot_Region67_ImputeMedians <- dfPerformance_Region67_ImputeMedians %>% 
  gather(key = "dataset", 
         value = "accuracy",
         train_accuracy:val_accuracy)

Dropout <- 0
l2 <- 1e-6

dfPlot_Region67_ImputeMedians %>% 
  filter(weight_decay == l2,
         dropout == Dropout) %>% 
  ggplot(aes(x = hidden_units, 
             y = accuracy,
             shape = dataset,
             col = factor(hidden_layers))) + 
  geom_jitter(width=10,
              alpha = 0.3,
              size = 4) + 
  coord_cartesian(ylim = c(0,1)) + 
  scale_x_continuous(breaks = seq(0,1000,200)) +
  scale_y_continuous(breaks = seq(0,1,0.2)) +
  scale_shape_discrete(labels = c("Training", "Validation")) + 
  labs(x = "Number of hidden units", 
       y = "Accuracy",
       shape = "Dataset",
       col = "Hidden layers",
       caption = "Training and validation sets generated by random sampling of coronal and sagittal ISH datasets",
       title = "Neural net performance (Labels: 67, Imputation: Medians)",
       subtitle = str_c("Dropout = ", Dropout, "; Weight decay = ", l2)) + 
  theme_bw()
```


```{r}
dfPlot_Region67_ImputeMedians_Means <- dfPlot_Region67_ImputeMedians %>% 
  group_by(dataset, hidden_units, hidden_layers, dropout, weight_decay) %>% 
  summarise(accuracy = mean(accuracy)) %>% 
  ungroup()

layers <- 3
l2 <- 1e-6

dfPlot_Region67_ImputeMedians_Means %>% 
  filter(hidden_layers == layers,
         weight_decay == l2) %>% 
  ggplot(aes(x = hidden_units, 
             y = accuracy,
             shape = dataset,
             col = factor(dropout))) + 
  geom_point(size = 6) + 
  geom_line(alpha = 0.5,
            size = 0.75) + 
  coord_cartesian(ylim = c(0,1)) + 
  scale_x_continuous(breaks = seq(0,1000,200)) +
  scale_y_continuous(breaks = seq(0,1,0.2)) +
  scale_shape_discrete(labels = c("Training", "Validation")) + 
  labs(x = "Number of hidden units", 
       y = "Accuracy",
       shape = "Dataset",
       col = "Dropout rate",
       caption = "Training and validation sets generated by random sampling of coronal and sagittal ISH datasets",
       title = "Neural net performance (Labels: 67, Imputation: Medians)",
       subtitle = str_c("Layers = ", layers, "; Weight decay = ", l2, "; Samples aggregated")) + 
  theme_bw()
```

```{r}
dfPlot_Region67_ImputeMedians_Means %>% 
  filter(dataset == "val_accuracy", 
         hidden_layers == layers,
         weight_decay == l2) %>% 
  ggplot(aes(x = hidden_units, 
             y = accuracy,
             col = factor(dropout))) + 
  geom_point(size = 6) + 
  geom_line(alpha = 0.5,
            size = 0.75) + 
  coord_cartesian(ylim = c(0.25,0.4)) + 
  scale_x_continuous(breaks = seq(0,1000,200)) +
  scale_y_continuous(breaks = seq(0.2, 0.4, 0.05)) +
  labs(x = "Number of hidden units", 
       y = "Accuracy",
       shape = "Dataset",
       col = "Dropout rate",
       caption = "Training and validation sets generated by random sampling of coronal and sagittal ISH datasets",
       title = "Neural net validation performance (Labels: 67, Imputation: Medians)",
       subtitle = str_c("Layers = ", layers, "; Weight decay = ", l2, "; Samples aggregated")) + 
  theme_bw()
```

```{r fig.width = 14, fig.height = 8}
dfPlot_Region67_ImputeMedians_Means %>% 
  filter(hidden_layers == 3,
         hidden_units %in% c(200, 500, 1000)) %>% 
  ggplot(aes(x = hidden_units, 
             y = accuracy,
             shape = dataset,
             col = factor(weight_decay))) + 
  geom_jitter(width=10,
              alpha = 1,
              size = 4) +
  geom_line(alpha = 0.5) +
  facet_wrap(~dropout, ncol = 4) + 
  coord_cartesian(ylim = c(0,1)) + 
  scale_x_continuous(breaks = seq(0,1000,200)) +
  scale_y_continuous(breaks = seq(0,1,0.2)) +
  scale_shape_discrete(labels = c("Training", "Validation")) + 
  labs(x = "Number of hidden units", 
       y = "Accuracy",
       shape = "Dataset",
       col = "Weight decay",
       caption = "Training and validation sets generated by random sampling of coronal and sagittal ISH datasets",
       title = "Neural net performance faceted by dropout rate (Labels: 67, Imputation: Medians)",
       subtitle = str_c("Layers = ", layers, "; Samples aggregated")) + 
  theme_bw()
```


```{r}
dfPlot_Region67_ImputeMedians_Means %>% 
  filter(dataset == "val_accuracy") %>% 
  filter(accuracy == max(accuracy))
```

```{r}
dfPlot_Region67_ImputeMedians_Means %>% 
  filter(hidden_units == 200,
         hidden_layers == 3,
         dropout == 0.25) %>% 
  spread(key = dataset, value = accuracy)
```



# Labels: 67; Imputation: KNN


```{r}
#Import data
labels <- "Region67"
imputation <- "ImputeKNN"
filepath <- str_c(path, "MLP_Validation_CoronalSagittalSampling_", labels, "_", imputation, ".csv")
dfPerformance_Region67_ImputeKNN <- suppressMessages(read_csv(filepath))

#Gather training and validation accuracies into one column
dfPlot_Region67_ImputeKNN <- dfPerformance_Region67_ImputeKNN %>% 
  gather(key = "dataset", 
         value = "accuracy",
         train_accuracy:val_accuracy)

Dropout <- 0
l2 <- 1e-6

dfPlot_Region67_ImputeKNN %>% 
  filter(weight_decay == l2,
         dropout == Dropout) %>% 
  ggplot(aes(x = hidden_units, 
             y = accuracy,
             shape = dataset,
             col = factor(hidden_layers))) + 
  geom_jitter(width=10,
              alpha = 0.3,
              size = 4) + 
  coord_cartesian(ylim = c(0,1)) + 
  scale_x_continuous(breaks = seq(0,1000,200)) +
  scale_y_continuous(breaks = seq(0,1,0.2)) +
  scale_shape_discrete(labels = c("Training", "Validation")) + 
  labs(x = "Number of hidden units", 
       y = "Accuracy",
       shape = "Dataset",
       col = "Hidden layers",
       caption = "Training and validation sets generated by random sampling of coronal and sagittal ISH datasets",
       title = "Neural net performance (Labels: 67, Imputation: KNN)",
       subtitle = str_c("Dropout = ", Dropout, "; Weight decay = ", l2)) + 
  theme_bw()
```

```{r}
dfPlot_Region67_ImputeKNN_Means <- dfPlot_Region67_ImputeKNN %>% 
  group_by(dataset, hidden_units, hidden_layers, dropout, weight_decay) %>% 
  summarise(accuracy = mean(accuracy)) %>% 
  ungroup()

layers <- 3
Dropout <- 0
l2 <- 1e-6

dfCompare_Region67_Imputation <- bind_rows(
  dfPlot_Region67_ImputeKNN_Means %>%
    mutate(imputation = "KNN") %>% 
    filter(hidden_layers == layers,
           dropout == Dropout,
           weight_decay == l2),
  dfPlot_Region67_ImputeMedians_Means %>% 
    mutate(imputation = "Medians") %>% 
    filter(hidden_layers == layers,
           dropout == Dropout, 
           weight_decay == l2)
)

ggplot(dfCompare_Region67_Imputation, aes(x = hidden_units, y = accuracy, shape = dataset, col = imputation)) + 
  geom_point(size = 6) + 
  geom_line(size = 0.75) + 
  coord_cartesian(ylim = c(0,1)) + 
  scale_x_continuous(breaks = seq(0,1000,200)) +
  scale_y_continuous(breaks = seq(0,1,0.2)) +
  scale_shape_discrete(labels = c("Training", "Validation")) + 
  labs(x = "Number of hidden units", 
       y = "Accuracy",
       shape = "Dataset",
       col = "Imputation strategy",
       caption = "Training and validation sets generated by random sampling of coronal and sagittal ISH datasets",
       title = "Impact of imputation strategy on neural net performance (Labels: 67)",
       subtitle = str_c("Layers = ", layers, "; Dropout = ", Dropout, "; Weight decay = ", l2, "; Samples aggregated")) + 
  theme_bw()
```

